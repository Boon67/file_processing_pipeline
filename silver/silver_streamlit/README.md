# Streamlit in Snowflake - Silver Data Management Interface

This folder contains the Streamlit in Snowflake application for the Silver Layer Data Transformation Pipeline.

## Files

- **`streamlit_app.py`** - Main Streamlit application
- **`snowflake.yml`** - Snowflake CLI deployment configuration - **RECOMMENDED**
- **`environment.yml`** - Python environment specification (Python version, Streamlit, packages) - **REQUIRED**

### Configuration Files Explained

#### 0. `snowflake.yml` (Recommended - Deployment Configuration)
Defines how the Streamlit app is deployed using the Snowflake CLI:
- App name and title
- Query warehouse
- Main file (streamlit_app.py)
- Stage name (SILVER_STREAMLIT)
- Artifacts to deploy (all app files)

This is the **modern, recommended approach** for deploying Streamlit apps. The `deploy_silver.sh` script automatically generates this file with values from your config file and uses it with the `snow streamlit deploy` command.

**Note:** The `snowflake.yml` in the repository is a template. The `deploy_silver.sh` script generates the actual file with your configuration values at deployment time.

Example (generated by deploy_silver.sh):
```yaml
definition_version: 2
entities:
  streamlit_app:
    type: streamlit
    identifier:
      name: Silver Transformation Manager
    query_warehouse: COMPUTE_WH
    main_file: streamlit_app.py
    stage: SILVER_STREAMLIT
    artifacts:
      - streamlit_app.py
      - environment.yml
```

#### 1. `environment.yml` (Required)
Defines the Python runtime environment for your Streamlit app:
- Python version (3.11)
- Streamlit version (>=1.28.0)
- Required packages (snowflake-snowpark-python, pandas, scikit-learn)

This file is **required** for Streamlit in Snowflake to work properly.

#### 2. `default.config` (Custom - Pipeline Configuration)
Your application-specific configuration (located in project root):
- Database, schema, warehouse names
- Stage names
- Task names

This is read by the Silver layer procedures and tasks.

## Deployment

The Streamlit app is automatically deployed as part of the Silver layer deployment.

From the project root directory, run:

```bash
# Deploy Silver layer (pipeline + Streamlit app)
./deploy_silver.sh

# Or with custom configuration
./deploy_silver.sh custom.config
```

This will:
1. Deploy the Silver data pipeline (schema, stages, tables, procedures, tasks)
2. Create Streamlit stage (`SILVER_STREAMLIT`) in PUBLIC schema
3. Upload configuration files
4. Deploy the Streamlit app using `snow streamlit deploy` (reads `snowflake.yml`)
   - Automatically uploads all artifacts (streamlit_app.py, environment.yml)
   - Creates/updates the Streamlit app in the **PUBLIC schema** (for centralized access)
5. Grant access to appropriate roles

### Manual Deployment (Optional)

If you need to deploy only the Streamlit app (after the pipeline is already deployed):

**Option 1: Using Snowflake CLI (Recommended)**
```bash
cd silver/silver_streamlit

# Edit snowflake.yml and replace placeholder values with your actual configuration
# Then deploy:
snow streamlit deploy --replace --database db_ingest_pipeline --schema PUBLIC
```

### Quick Update (Streamlit Files Only)

To push only Streamlit app updates without redeploying the entire pipeline:

```bash
# Upload the updated Streamlit app
snow stage copy silver/silver_streamlit/streamlit_app.py @db_ingest_pipeline.SILVER.SILVER_STREAMLIT/ --overwrite

# Upload the environment file (if changed)
snow stage copy silver/silver_streamlit/environment.yml @db_ingest_pipeline.SILVER.SILVER_STREAMLIT/ --overwrite
```

The app will automatically reload with the new code on the next page refresh in Snowsight.

## Accessing the App

After deployment, access the app via Snowsight:

1. Navigate to Snowsight
2. Click on "Streamlit" in the left sidebar
3. Find "SILVER_DATA_MANAGER" in the list
4. Click to open

## Features

### üìê Target Table Designer Tab
- **View Tables**: Browse all target table definitions with summary statistics
- **Add Columns**: Define columns with data types, defaults, and descriptions
- **Edit Columns**: Modify existing column definitions inline using data editor
- **Delete Columns**: Remove individual columns from table definitions
- **Delete Tables**: Remove entire table definitions
- **Create Tables**: Automatically create/update physical tables from definitions
- **Schema Validation**: Automatic validation of data types and structure

### üó∫Ô∏è Field Mapper Tab
- **Manual Mappings**: Create Bronze ‚Üí Silver field mappings manually
- **ML Auto-Mapping**: Use machine learning pattern matching for field suggestions
  - Exact match detection
  - Substring matching
  - Sequence similarity (Levenshtein distance)
  - TF-IDF semantic similarity
- **LLM Cortex AI**: Leverage Snowflake Cortex AI for semantic field mapping
  - Uses models like llama3.1-70b for intelligent suggestions
  - Understands field context and relationships
- **Confidence Scoring**: All auto-mappings include confidence scores
- **Approval Workflow**: Review and approve suggested mappings before use
- **Mapping Summary**: View all active mappings by target table

### ‚öôÔ∏è Rules Engine Tab
- **Data Quality Rules**: Null checks, format validation, range checks
- **Business Logic Rules**: Calculations, lookups, conditional transformations
- **Standardization Rules**: Date normalization, name casing, code mapping
- **Deduplication Rules**: Exact/fuzzy matching with conflict resolution
- **Priority Management**: Set rule execution order
- **Error Actions**: Configure REJECT, QUARANTINE, or LOG for violations
- **Rule Testing**: Test rules before applying to production data

### üìä Transformation Monitor Tab
- View recent transformation batches
- Track processing status (PENDING, PROCESSING, SUCCESS, FAILED)
- Monitor batch metrics (records processed, duration, quality scores)
- View detailed error messages for failed batches
- Trigger manual transformations
- Configure batch size and incremental processing
- View transformation history and trends

### üìà Data Quality Metrics Tab
- Quality dashboard with pass/fail rates
- View quarantined records with violation details
- Track quality trends over time
- Resolve or reprocess quarantined records
- View rule execution statistics
- Quality score tracking by table and batch

### üîß Task Management Tab
- **Real-time Task Status**: View the current state of all Silver layer tasks
- **Individual Task Control**:
  - **Execute Now**: Run any task immediately without waiting for the schedule
  - **Resume**: Start a suspended task
  - **Suspend**: Pause a running task
- **Task History**: View recent executions (last 24 hours) with:
  - Execution status (SUCCESS, FAILED, SKIPPED)
  - Scheduled and completion times
  - Error messages for failed runs
- **Bulk Actions**:
  - Resume all Silver tasks at once
  - Suspend all Silver tasks at once
- **Task Dependencies**: Visual display of task predecessors and scheduling

#### Use Cases for Task Management

1. **Maintenance Windows**: Suspend all tasks before performing maintenance
   ```
   Click "‚è∏Ô∏è Suspend All Tasks" ‚Üí Perform maintenance ‚Üí Click "‚ñ∂Ô∏è Resume All Tasks"
   ```

2. **Immediate Processing**: Transform data immediately after Bronze ingestion
   ```
   Click "üîÑ Execute Transformation Now" ‚Üí Data transforms within seconds
   ```

3. **Troubleshooting**: Investigate task failures
   ```
   View task history ‚Üí Check error messages ‚Üí Fix issue ‚Üí Resume task
   ```

4. **Cost Control**: Pause processing during low-priority periods
   ```
   Suspend tasks overnight or weekends ‚Üí Resume during business hours
   ```

## Configuration

The app automatically loads configuration from `default.config` (or `custom.config` if available) stored in the `@PUBLIC.CONFIG_STAGE`:

### Configuration Loading
1. **First Priority**: Checks for `custom.config` in CONFIG_STAGE
2. **Fallback**: Uses `default.config` if custom not found
3. **Default Values**: Uses hardcoded defaults if neither file is available

### Configuration Parameters
The app reads these settings from the config file:

**Database Configuration:**
- `DATABASE_NAME` - Database name (default: `db_ingest_pipeline`)
- `SCHEMA_NAME` - Bronze schema name (default: `BRONZE`)
- `SILVER_SCHEMA_NAME` - Silver schema name (default: `SILVER`)
- `WAREHOUSE_NAME` - Warehouse for queries (default: `COMPUTE_WH`)

**Silver Layer Settings:**
- `SILVER_STAGE_NAME` - Silver stage (default: `SILVER_STAGE`)
- `SILVER_CONFIG_STAGE_NAME` - Config stage (default: `SILVER_CONFIG`)
- `SILVER_STREAMLIT_STAGE_NAME` - Streamlit stage (default: `SILVER_STREAMLIT`)
- `SILVER_TRANSFORM_SCHEDULE_MINUTES` - Transform frequency (default: `15`)
- `SILVER_STREAMLIT_APP_NAME` - App name (default: `SILVER_DATA_MANAGER`)

**Processing Configuration:**
- `DEFAULT_LLM_MODEL` - LLM model for mapping (default: `llama3.1-70b`)
- `DEFAULT_BATCH_SIZE` - Records per batch (default: `10000`)

### Viewing Configuration
The app displays the current configuration in an expandable section at the top of the page:
1. Click "‚öôÔ∏è Configuration" to expand
2. View all loaded settings organized by category
3. Verify which config file was loaded (shown in success message)

### Updating Configuration

**Option 1: Update Config File**
```bash
# Edit the configuration file
vim default.config

# Or create a custom config
cp default.config custom.config
vim custom.config

# Redeploy to upload new config
./deploy_silver.sh

# Refresh the Streamlit app
```

**Option 2: Direct Stage Upload**
```bash
# Upload updated config directly to stage
snow sql -q "PUT file://default.config @db_ingest_pipeline.PUBLIC.CONFIG_STAGE OVERWRITE=TRUE;"

# Refresh the app (config cache expires after 5 minutes)
```

### Configuration Cache
- Configuration is cached for 5 minutes (`ttl=300`)
- Changes take effect after cache expiry or app restart
- Force refresh by reloading the app page

## Development

To test the app locally (not recommended, use Streamlit in Snowflake instead):

```bash
# Install dependencies
pip install streamlit snowflake-snowpark-python pandas scikit-learn

# Set up credentials
# Create .env file with Snowflake credentials

# Run locally
streamlit run streamlit_app.py
```

**Note:** The app is designed to run in Snowflake and uses `get_active_session()`. For local testing, you would need to modify the session initialization code.

## Troubleshooting

### App not showing in Snowsight
- Ensure you have the correct role (check grants)
- Run: `SHOW STREAMLITS IN SCHEMA PUBLIC;` to verify the app exists
- Verify you have access to the PUBLIC schema

### Configuration errors
- Check that the Silver layer is deployed (`./deploy_silver.sh` first)
- Verify the database and schema exist
- Check that stages are created
- Ensure Bronze layer is deployed and operational

### Mapping errors
- Verify Bronze layer has data in RAW_DATA_TABLE
- Check that target schemas are defined
- Ensure field names are valid
- Review confidence scores for auto-mappings

### Transformation failures
- Check warehouse is running and has sufficient resources
- Verify field mappings are approved
- Review transformation rules for conflicts
- Check quarantine records for data quality issues
- Ensure Bronze data is in expected format

### Task execution issues
- Verify tasks are resumed (not suspended)
- Check task history for error messages
- Ensure Bronze tasks have completed successfully
- Verify warehouse permissions

## Security

The app runs in Snowflake and uses your authenticated session. No external credentials are required, and all data stays within Snowflake's secure environment.

Role-based access control (RBAC):
- **ADMIN**: Full control over Streamlit app deployment and management
- **READWRITE**: Can access and interact with the Streamlit app
- **READONLY**: Can view the Streamlit app

## Integration with Bronze Layer

The Silver layer Streamlit app integrates seamlessly with the Bronze layer:
- Reads from `BRONZE.RAW_DATA_TABLE`
- Monitors Bronze task completion
- Triggered automatically after Bronze processing
- Shares the same database and warehouse
- Uses consistent role-based access control

## üé® UI/UX Features

### Design Principles
1. **Metadata-Driven**: All configuration via UI, no code changes needed
2. **Visual Feedback**: Clear status indicators and progress bars
3. **Guided Workflow**: Step-by-step process for complex tasks
4. **Error Prevention**: Validation before submission
5. **Contextual Help**: Tooltips and examples throughout

### User Experience Enhancements
- **Data Editor**: Inline editing of tables and mappings
- **Confidence Scores**: Visual indicators for mapping quality
- **Approval Workflow**: Review before applying changes
- **Batch Operations**: Bulk approve/reject mappings
- **Real-Time Validation**: Immediate feedback on inputs
- **Export/Import**: Download and upload configurations

### Accessibility
- Keyboard shortcuts for common actions
- Screen reader support
- High contrast mode
- Responsive layout for different screen sizes

## üìä App Architecture

### Technology Stack
- **Frontend**: Streamlit (>=1.28.0)
- **Backend**: Snowflake Snowpark Python
- **ML Libraries**: scikit-learn (for pattern matching)
- **Database**: Snowflake (native)
- **AI**: Snowflake Cortex (for LLM mapping)

### Component Diagram
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Streamlit UI (Browser)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇSch.‚îÇMapper‚îÇ Rules ‚îÇMonitor ‚îÇQuality ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ (HTTPS)
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Streamlit in Snowflake Runtime         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  streamlit_app.py                    ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Schema management                 ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Field mapping (Manual/ML/LLM)     ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Rules configuration               ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Transformation monitoring         ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Quality dashboards                ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ (Snowpark API)
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Silver Layer (Snowflake)            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Metadata   ‚îÇ Mappings ‚îÇ   Rules     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Tables     ‚îÇ Engine   ‚îÇ   Engine    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Transform  ‚îÇ Quality  ‚îÇ   Tasks     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Procedures ‚îÇ Metrics  ‚îÇ   Pipeline  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Bronze Layer                        ‚îÇ
‚îÇ  RAW_DATA_TABLE (Source data)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üî¨ Advanced Features

### ML-Based Field Mapping
The app includes four ML algorithms for auto-mapping:

1. **Exact Match** (Confidence: 1.0)
   - Exact field name match (case-insensitive)
   - Fastest, most accurate

2. **Substring Match** (Confidence: 0.85-0.95)
   - One field name contains the other
   - Good for abbreviated names

3. **Sequence Similarity** (Confidence: 0.70-0.90)
   - Levenshtein distance calculation
   - Handles typos and variations

4. **TF-IDF Similarity** (Confidence: 0.60-0.85)
   - Term frequency analysis
   - Best for semantic similarity

### LLM-Based Semantic Mapping
Uses Snowflake Cortex AI for intelligent mapping:

**Features:**
- Understands business context
- Handles abbreviations (DOB ‚Üí DATE_OF_BIRTH)
- Recognizes synonyms
- Suggests transformations
- Provides reasoning

**Models Available:**
- `llama3.1-70b` (default) - Best accuracy
- `llama3.1-8b` - Faster, lower cost
- `mistral-large` - Alternative option

**Customization:**
- Adjustable temperature (0.0-1.0)
- Custom prompts
- Context injection
- Batch processing

### Rules Engine Visualization
The app provides visual tools for rule management:

**Rule Builder:**
- Drag-and-drop rule creation
- SQL expression builder
- Test with sample data
- Validation before saving

**Rule Execution Graph:**
- Visual dependency tree
- Priority ordering
- Impact analysis
- Performance metrics

**Rule Testing:**
- Test rules on sample data
- Preview results before applying
- A/B testing support
- Rollback capability

## üîß Customization Guide

### Adding Custom Tabs
Extend the app with new functionality:

```python
# In streamlit_app.py
tabs = st.tabs([
    "üìê Target Table Designer",
    "üó∫Ô∏è Field Mapper",
    "‚öôÔ∏è Rules Engine",
    "üìä Transformation Monitor",
    "üìà Data Quality Metrics",
    "üîß Task Management",
    "üÜï Custom Tab"  # Add your tab
])

with tabs[6]:  # Custom tab
    st.header("Custom Feature")
    # Your implementation
```

### Custom Mapping Algorithms
Add your own mapping algorithm:

```python
def custom_mapping_algorithm(source_fields, target_fields):
    """Custom field mapping logic"""
    mappings = []
    for source in source_fields:
        for target in target_fields:
            # Your matching logic
            confidence = calculate_confidence(source, target)
            if confidence > 0.6:
                mappings.append({
                    'source': source,
                    'target': target,
                    'confidence': confidence,
                    'method': 'CUSTOM'
                })
    return mappings
```

### Custom Quality Metrics
Define custom quality measurements:

```python
def custom_quality_metric(session, table_name):
    """Calculate custom quality metric"""
    query = f"""
        SELECT 
            COUNT(*) * 100.0 / (SELECT COUNT(*) FROM {table_name})
        FROM {table_name}
        WHERE your_custom_condition
    """
    result = session.sql(query).collect()
    return result[0][0]
```

### Theming
Customize the app appearance:

```python
# Add to .streamlit/config.toml
[theme]
primaryColor = "#1f77b4"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#262730"
font = "sans serif"
```

## üêõ Debugging & Troubleshooting

### Enable Debug Mode
```python
# In streamlit_app.py
DEBUG = True

if DEBUG:
    st.sidebar.expander("Debug Info").write({
        "Session": st.session_state,
        "User": session.get_current_user(),
        "Role": session.get_current_role(),
        "Database": session.get_current_database(),
        "Schema": session.get_current_schema()
    })
```

### Common Issues & Solutions

**Issue: Mappings not saving**
- Check approved flag is TRUE
- Verify target table exists
- Check for duplicate mappings

**Issue: LLM mapping slow**
- Reduce batch size
- Use smaller model (llama3.1-8b)
- Increase timeout

**Issue: Rules not applying**
- Check rule enabled flag
- Verify rule_logic syntax
- Test rule in SQL worksheet

**Issue: Transformation fails**
- Check Bronze data exists
- Verify field mappings approved
- Review quarantine_records

### Performance Monitoring
```python
import time

# Add timing to operations
start = time.time()
result = expensive_operation()
duration = time.time() - start

st.sidebar.metric("Operation Time", f"{duration:.2f}s")
```

### Logging
```sql
-- View app execution logs
SELECT *
FROM TABLE(INFORMATION_SCHEMA.STREAMLIT_HISTORY())
WHERE STREAMLIT_NAME = 'SILVER_DATA_MANAGER'
ORDER BY START_TIME DESC
LIMIT 100;
```

## üìà Performance Optimization

### Query Optimization
- Use indexed columns for filtering
- Apply LIMIT clauses
- Cache expensive queries
- Use materialized views

### UI Optimization
- Lazy load large datasets
- Paginate results
- Use st.cache_data decorator
- Minimize reruns

### Best Practices
1. Limit result sets to 1,000 rows
2. Use filters before loading data
3. Cache frequently accessed data
4. Batch operations when possible
5. Monitor warehouse usage

## üîê Security Best Practices

### Data Protection
- Never display sensitive data in logs
- Use masking policies for PII
- Implement row-level security
- Audit all data access

### Access Control
- Use role-based permissions
- Implement approval workflows
- Log all configuration changes
- Restrict production access

### Compliance
- GDPR: Right to erasure
- HIPAA: Audit trails
- SOC 2: Monitoring and alerting
- Data lineage tracking

## üìö Additional Resources

### Internal Documentation
- [Silver Layer README](../README.md) (includes Quick Start)
- [Bronze Layer README](../../bronze/README.md)
- [Main Project README](../../README.md)
- [Sample Data Guide](../../sample_data/README.md)

### External Resources
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)
- [Snowflake Cortex AI Documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex)
- [Snowpark Python API](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)

### Community
- [Streamlit Community Forum](https://discuss.streamlit.io/)
- [Snowflake Community](https://community.snowflake.com/)

---

**Last Updated**: January 2, 2026  
**Version**: 2.0  
**Status**: Production Ready ‚úÖ  
**App Name**: SILVER_DATA_MANAGER  
**Features**: 6 tabs, 3 mapping methods, 5 rule types


