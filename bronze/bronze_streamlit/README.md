# Streamlit in Snowflake - File Upload Interface

This folder contains the Streamlit in Snowflake application for the File Processing Pipeline.

## Files

- **`streamlit_app.py`** - Main Streamlit application
- **`snowflake.yml`** - Snowflake CLI deployment configuration - **RECOMMENDED**
- **`environment.yml`** - Python environment specification (Python version, Streamlit, packages) - **REQUIRED**
- **`requirements.txt`** - Python dependencies (for reference, automatically managed by Snowflake)
- **`env.example`** - Environment variables template (not needed for Streamlit in Snowflake)
- **`deploy_streamlit.sql`** - SQL script for manual Streamlit app deployment (legacy)

### Configuration Files Explained

#### 0. `snowflake.yml` (Recommended - Deployment Configuration)
Defines how the Streamlit app is deployed using the Snowflake CLI:
- App name and title
- Query warehouse
- Main file (streamlit_app.py)
- Stage name (STREAMLIT_STAGE)
- Artifacts to deploy (all app files)

This is the **modern, recommended approach** for deploying Streamlit apps. The `deploy.sh` script automatically generates this file with values from your config file and uses it with the `snow streamlit deploy` command.

**Note:** The `snowflake.yml` in the repository is a template. The `deploy.sh` script generates the actual file with your configuration values at deployment time.

Example (generated by deploy.sh):
```yaml
definition_version: 2
entities:
  streamlit_app:
    type: streamlit
    identifier:
      name: Bronze Ingestion Pipeline
    query_warehouse: COMPUTE_WH
    main_file: streamlit_app.py
    stage: STREAMLIT_STAGE
    artifacts:
      - streamlit_app.py
      - environment.yml
```

#### 1. `environment.yml` (Required)
Defines the Python runtime environment for your Streamlit app:
- Python version (3.11)
- Streamlit version (1.51.0)
- Required packages (snowflake-snowpark-python)

This file is **required** for Streamlit in Snowflake to work properly.

#### 2. `default.config` (Custom - Pipeline Configuration)
Your application-specific configuration (located in project root):
- Database, schema, warehouse names
- Stage names
- Task names

This is read by `streamlit_app.py` from `@PUBLIC.CONFIG_STAGE`.

## Deployment

The Streamlit app is automatically deployed as part of the main pipeline deployment.

From the project root directory, run:

```bash
# Deploy everything (pipeline + Streamlit app)
./deploy.sh

# Or with custom configuration
./deploy.sh production.config
```

This will:
1. Deploy the data pipeline (database, roles, stages, tables, tasks)
2. Create Streamlit stages (`STREAMLIT_STAGE`, `CONFIG_STAGE`) in PUBLIC schema
3. Upload configuration files to `@PUBLIC.CONFIG_STAGE`
4. Deploy the Streamlit app using `snow streamlit deploy` (reads `snowflake.yml`)
   - Automatically uploads all artifacts (streamlit_app.py, environment.yml)
   - Creates/updates the Streamlit app in the **PUBLIC schema**
5. Grant access to appropriate roles

**Important:** The app is deployed to the **PUBLIC schema**, not the pipeline schema (BRONZE). This allows:
- Centralized configuration management
- Easier access control
- Separation of concerns between UI and data pipeline

### Manual Deployment (Optional)

If you need to deploy only the Streamlit app (after the pipeline is already deployed):

**Option 1: Using Snowflake CLI (Recommended)**
```bash
cd streamlit

# Edit snowflake.yml and replace placeholder values with your actual configuration
# Then deploy:
snow streamlit deploy --replace --database db_ingest_pipeline --schema PUBLIC
```

**Option 2: Using SQL Script (Legacy)**
```bash
# Use the SQL script with variable replacement
snow sql -f streamlit/deploy_streamlit.sql
```

Or manually edit the variables in `streamlit/deploy_streamlit.sql` and run it directly in Snowsight.

### Quick Update (Streamlit Files Only)

To push only Streamlit app updates without redeploying the entire pipeline:

```bash
# Upload the updated Streamlit app
snow stage copy streamlit/streamlit_app.py @db_ingest_pipeline.PUBLIC.STREAMLIT_STAGE/ --overwrite

# Upload the environment file (if changed)
snow stage copy streamlit/environment.yml @db_ingest_pipeline.PUBLIC.STREAMLIT_STAGE/ --overwrite
```

The app will automatically reload with the new code on the next page refresh in Snowsight.

## Accessing the App

After deployment, access the app via Snowsight:

1. Navigate to Snowsight
2. Click on "Streamlit" in the left sidebar
3. Find "file_upload_app" in the list
4. Click to open

## Features

### ğŸ“¤ Upload Files Tab
- **TPA Selection**: Choose Third Party Administrator (TPA) from dropdown or enter custom name
  - Predefined options: provider_a, provider_b, provider_c, provider_d, provider_e
  - Custom option: Enter any custom TPA name
  - Files are uploaded to TPA-specific subfolders: `@SRC/{tpa_name}/`
- Drag-and-drop or browse to upload CSV/Excel files
- Multi-file upload support
- Real-time file validation (type and size)
- Progress tracking with TPA information
- Upload summary with success/failure counts
- Automatic TPA metadata extraction and storage

### ğŸ“Š Processing Status Tab
- View file processing status in real-time
- **TPA Column**: See which TPA each file belongs to
- Filter by status (PENDING, PROCESSING, SUCCESS, FAILED)
- Filter by file type (CSV, EXCEL)
- **Filter by TPA**: Filter files by Third Party Administrator
- Metrics dashboard with success rates
- Detailed error messages for failed files
- Refresh capability
- Download results as CSV

### ğŸ“‚ File Stages Tab
- Browse all stages (`@SRC`, `@COMPLETED`, `@ERROR`, `@ARCHIVE`)
- List all files in each stage
- View file metadata (size, last modified, MD5 hash)
- File count summary per stage

### ğŸ“‹ Raw Data Viewer Tab (NEW)
- **View RAW_DATA_TABLE contents**: Browse all ingested data
- **Summary Metrics**: Total rows, unique files, unique TPAs, date range
- **Filter by TPA**: Select one or more TPAs to view their data
- **Filter by File**: Select specific files to view
- **Pagination**: Configurable rows per page (50-1000)
- **JSON Data Display**: View raw data in JSON format
- **Sample Row Details**: Expand to see detailed JSON structure
- **Download**: Export filtered data as CSV
- **Real-time Refresh**: Update view with latest data

### âš™ï¸ Task Management Tab
- **Real-time Task Status**: View the current state of all pipeline tasks
- **Individual Task Control**:
  - **Process Now**: Execute any task immediately without waiting for the schedule
  - **Resume**: Start a suspended task
  - **Suspend**: Pause a running task
- **Task History**: View recent executions (last 24 hours) with:
  - Execution status (SUCCESS, FAILED, SKIPPED)
  - Scheduled and completion times
  - Error messages for failed runs
- **Bulk Actions**:
  - Resume all tasks at once
  - Suspend all tasks at once
  - Execute discovery task immediately
- **Task Dependencies**: Visual display of task predecessors and scheduling

#### Use Cases for Task Management

1. **Maintenance Windows**: Suspend all tasks before performing maintenance
   ```
   Click "â¸ï¸ Suspend All Tasks" â†’ Perform maintenance â†’ Click "â–¶ï¸ Resume All Tasks"
   ```

2. **Immediate Processing**: Upload files and process them immediately
   ```
   Upload files â†’ Click "ğŸ”„ Execute Discovery Now" â†’ Files process within seconds
   ```

3. **Troubleshooting**: Investigate task failures
   ```
   View task history â†’ Check error messages â†’ Fix issue â†’ Resume task
   ```

4. **Cost Control**: Pause processing during low-priority periods
   ```
   Suspend tasks overnight or weekends â†’ Resume during business hours
   ```

## Configuration

The app automatically loads configuration from `@PUBLIC.CONFIG_STAGE`:
- First tries to load `custom.config` (if you deployed with a custom config)
- Falls back to `default.config`
- All pipeline settings (database, schema, stages, tasks) are read from the config file

**Configuration File Location:** `@<database>.PUBLIC.CONFIG_STAGE`

**To Update Configuration:**
1. Edit `default.config` or create a custom config file
2. Run `./deploy.sh` to redeploy with the new configuration
3. Refresh the Streamlit app to load the new settings

The app displays the loaded configuration as read-only fields in the sidebar.

## Development

To test the app locally (not recommended, use Streamlit in Snowflake instead):

```bash
# Install dependencies
pip install -r requirements.txt

# Set up credentials
cp env.example .env
# Edit .env with your Snowflake credentials

# Export environment variables
export $(cat .env | xargs)

# Run locally
streamlit run streamlit_app.py
```

**Note:** The app is designed to run in Snowflake and uses `get_active_session()`. For local testing, you would need to modify the session initialization code.

## Troubleshooting

### App not showing in Snowsight
- Ensure you have the correct role (check grants)
- Run: `SHOW STREAMLITS IN SCHEMA;` to verify the app exists

### Upload failures
- Check warehouse is running
- Verify stage permissions
- Check file size limits (max 100MB per file)

### Connection errors
- Ensure the pipeline is deployed (`./deploy.sh` first)
- Verify the database and schema exist
- Check that stages are created

## Security

The app runs in Snowflake and uses your authenticated session. No external credentials are required, and all data stays within Snowflake's secure environment.

### Security Features
- **Session-Based Auth**: Uses Snowflake session authentication
- **Role-Based Access**: Respects Snowflake role hierarchy
- **No Credential Storage**: No passwords or keys stored
- **Encrypted Communication**: TLS 1.2+ for all connections
- **Audit Trail**: All operations logged in Snowflake

### Access Control
- **File Upload**: Requires WRITE permission on @SRC stage
- **Task Management**: Requires OPERATE privilege on tasks
- **Data Viewing**: Requires SELECT on tables
- **Stage Browsing**: Requires READ on stages

## ğŸ“Š App Architecture

### Technology Stack
- **Frontend**: Streamlit 1.51.0
- **Backend**: Snowflake Snowpark Python
- **Database**: Snowflake (native)
- **Deployment**: Snowflake CLI

### Component Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Streamlit UI (Browser)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Upload â”‚ Status â”‚ Stages â”‚Tasksâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ (HTTPS)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit in Snowflake Runtime    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  streamlit_app.py               â”‚â”‚
â”‚  â”‚  - Session management           â”‚â”‚
â”‚  â”‚  - UI rendering                 â”‚â”‚
â”‚  â”‚  - Data queries                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ (Snowpark API)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Snowflake Database             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tables  â”‚ Stages  â”‚   Tasks    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¨ UI/UX Features

### Design Principles
1. **Simplicity**: Clean, intuitive interface
2. **Efficiency**: Minimal clicks to accomplish tasks
3. **Feedback**: Clear status messages and progress indicators
4. **Responsiveness**: Fast loading and updates
5. **Consistency**: Uniform design across tabs

### User Experience Enhancements
- **Drag-and-Drop**: Easy file upload
- **Real-Time Updates**: Automatic refresh of status
- **Color Coding**: Visual status indicators (green/red/yellow)
- **Collapsible Sections**: Reduce clutter
- **Tooltips**: Contextual help
- **Error Messages**: Clear, actionable error text

### Accessibility
- Keyboard navigation support
- Screen reader compatible
- High contrast mode support
- Responsive layout

## ğŸ“ˆ Performance Optimization

### App Performance
- **Caching**: Uses `@st.cache_data` for expensive queries
- **Session State**: Maintains state across reruns
- **Lazy Loading**: Loads data only when needed
- **Pagination**: Limits result sets for large tables

### Query Optimization
- **Indexed Queries**: Uses indexed columns for filtering
- **Result Limits**: Applies LIMIT clauses
- **Efficient Joins**: Minimizes join complexity
- **Materialized Views**: Uses views for complex queries

### Best Practices
1. Limit result sets to 1,000 rows
2. Use filters to reduce data volume
3. Cache frequently accessed data
4. Avoid expensive operations in UI thread

## ğŸ”§ Customization Guide

### Changing Colors
Edit the color scheme in `streamlit_app.py`:

```python
# Custom color scheme
SUCCESS_COLOR = "#28a745"
ERROR_COLOR = "#dc3545"
WARNING_COLOR = "#ffc107"
INFO_COLOR = "#17a2b8"
```

### Adding New Tabs
Add a new tab to the interface:

```python
# Add to tab list
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“¤ Upload Files",
    "ğŸ“Š Processing Status",
    "ğŸ“‚ Stage Files",
    "âš™ï¸ Task Management",
    "ğŸ†• New Tab"  # Your new tab
])

# Implement tab content
with tab5:
    st.header("New Feature")
    # Your code here
```

### Custom Queries
Add custom data queries:

```python
def get_custom_metrics(session):
    """Get custom metrics from database"""
    query = """
        SELECT 
            metric_name,
            metric_value,
            measurement_time
        FROM custom_metrics
        ORDER BY measurement_time DESC
        LIMIT 10
    """
    return session.sql(query).collect()
```

### Configuration Options
Customize app behavior via session state:

```python
# Set in sidebar
st.sidebar.number_input(
    "Refresh Interval (seconds)",
    min_value=5,
    max_value=300,
    value=30,
    key="refresh_interval"
)

# Use in app
if st.session_state.refresh_interval:
    time.sleep(st.session_state.refresh_interval)
    st.rerun()
```

## ğŸ› Debugging

### Enable Debug Mode
Add debug information to the app:

```python
# In streamlit_app.py
DEBUG = True  # Set to False for production

if DEBUG:
    st.sidebar.write("Debug Info:")
    st.sidebar.json({
        "session_id": st.session_state.get("session_id"),
        "user": session.get_current_user(),
        "role": session.get_current_role(),
        "warehouse": session.get_current_warehouse()
    })
```

### View Logs
Check Streamlit logs in Snowflake:

```sql
-- View Streamlit execution logs
SELECT *
FROM TABLE(INFORMATION_SCHEMA.STREAMLIT_HISTORY())
WHERE STREAMLIT_NAME = 'BRONZE_INGESTION_PIPELINE'
ORDER BY START_TIME DESC
LIMIT 100;
```

### Common Debug Steps
1. Check session connection
2. Verify role permissions
3. Test queries in SQL worksheet
4. Check warehouse status
5. Review error messages

## ğŸ“š Additional Resources

### Internal Documentation
- [Bronze Layer README](../README.md) - Bronze layer details
- [Main Project README](../../README.md) - Project overview
- [Deployment Guide](DEPLOYMENT.md) - Deployment instructions

### External Resources
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)
- [Snowpark Python API](https://docs.snowflake.com/en/developer-guide/snowpark/python/index)

### Community
- [Streamlit Community Forum](https://discuss.streamlit.io/)
- [Snowflake Community](https://community.snowflake.com/)

---

**Last Updated**: January 2, 2026  
**Version**: 2.0  
**Status**: Production Ready âœ…  
**App Name**: BRONZE_INGESTION_PIPELINE


